{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем, почему модель падает на этапе сохранения чекпоинта"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    y = copier(x, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\n",
    "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 190, in deepcopy\n",
    "    y = _reconstruct(x, rv, 1, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 334, in _reconstruct\n",
    "    state = deepcopy(state, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 163, in deepcopy\n",
    "    y = copier(x, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\n",
    "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 190, in deepcopy\n",
    "    y = _reconstruct(x, rv, 1, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 334, in _reconstruct\n",
    "    state = deepcopy(state, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 163, in deepcopy\n",
    "    y = copier(x, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\n",
    "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 163, in deepcopy\n",
    "    y = copier(x, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 230, in _deepcopy_list\n",
    "    y.append(deepcopy(a, memo))\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 163, in deepcopy\n",
    "    y = copier(x, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 237, in _deepcopy_tuple\n",
    "    y.append(deepcopy(a, memo))\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 163, in deepcopy\n",
    "    y = copier(x, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\n",
    "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 190, in deepcopy\n",
    "    y = _reconstruct(x, rv, 1, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 334, in _reconstruct\n",
    "    state = deepcopy(state, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 163, in deepcopy\n",
    "    y = copier(x, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 257, in _deepcopy_dict\n",
    "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"/usr/lib/python2.7/copy.py\", line 174, in deepcopy\n",
    "    y = copier(memo)\n",
    "TypeError: cannot deepcopy this pattern object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anatoly/Desktop/squad\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from models import RNet, FastQA\n",
    "from data import BatchGen, load_dataset\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['model'] = 'fastqa'\n",
    "args['hdim']  = 300\n",
    "args['batch_size'] = 64\n",
    "args['nb_epochs'] = 50\n",
    "args['optimizer'] = 'Adam'\n",
    "args['lr'] = 0.001\n",
    "args['name'] = ''\n",
    "args['loss'] = 'categorical_crossentropy'\n",
    "args['dropout'] = 0\n",
    "\n",
    "args['train_data'] = 'data/train_data.pkl'\n",
    "args['valid_data'] = 'data/valid_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, RepeatVector, Masking, Dropout, Flatten, Activation, Reshape, Lambda, Permute, merge, multiply, concatenate\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastQA(Model):\n",
    "    def __init__(self, inputs=None, outputs=None,\n",
    "                       N=None, M=None, unroll=False,\n",
    "                       hdim=300, word2vec_dim=300, dropout_rate=0.2,\n",
    "                       **kwargs):\n",
    "        # Load model from config\n",
    "        if inputs is not None and outputs is not None:\n",
    "            super(FastQA, self).__init__(inputs=inputs,\n",
    "                                       outputs=outputs,\n",
    "                                       **kwargs)\n",
    "            return\n",
    "        \n",
    "        '''Dimensions'''\n",
    "        B = None\n",
    "        H = hdim\n",
    "        W = word2vec_dim\n",
    "\n",
    "        '''Inputs'''\n",
    "        P = Input(shape=(N, W), name='P')\n",
    "        Q = Input(shape=(M, W), name='Q')\n",
    "\n",
    "        '''Word in question binary'''\n",
    "        def wiq_feature(P,Q):\n",
    "            '''\n",
    "            Binary feature mentioned in the paper.\n",
    "            For each word in passage returns if that word is present in question.\n",
    "            '''\n",
    "            slice = []\n",
    "            for i in range(N):\n",
    "                word_sim = K.tf.equal(W, K.tf.reduce_sum(K.tf.cast(K.tf.equal(K.tf.expand_dims(P[:, i, :],1), Q), K.tf.int32), axis=2))\n",
    "                question_sim = K.tf.equal(M, K.tf.reduce_sum(K.tf.cast(word_sim, K.tf.int32), axis=1))\n",
    "                slice.append(K.tf.cast(question_sim, K.tf.float32))\n",
    "\n",
    "            wiqout = K.tf.expand_dims(K.tf.stack(slice, axis=1),2)\n",
    "            return wiqout\n",
    "\n",
    "        wiq_p = Lambda(lambda arg: wiq_feature(arg[0],arg[1]))([P,Q])\n",
    "        wiq_q = Lambda(lambda q: K.tf.ones([K.tf.shape(Q)[0], M, 1], dtype=K.tf.float32))(Q)\n",
    "\n",
    "        passage_input = P\n",
    "        question_input = Q\n",
    "        #passage_input = Lambda(lambda arg: concatenate([arg[0], arg[1]], axis=2))([P, wiq_p])\n",
    "        #question_input = Lambda(lambda arg: concatenate([arg[0], arg[1]], axis=2))([Q, wiq_q])\n",
    "\n",
    "        '''Encoding'''\n",
    "        encoder = Bidirectional(LSTM(units=W,\n",
    "                           return_sequences=True,\n",
    "                           dropout=dropout_rate,\n",
    "                           unroll=unroll))\n",
    "\n",
    "        passage_encoding = passage_input\n",
    "        passage_encoding = encoder (passage_encoding)\n",
    "        passage_encoding = TimeDistributed(\n",
    "            Dense(W,\n",
    "                use_bias=False,\n",
    "                trainable=True,\n",
    "                weights=np.concatenate((np.eye(W),np.eye(W)), axis=1))) (passage_encoding)\n",
    "\n",
    "        question_encoding = question_input\n",
    "        question_encoding = encoder(question_encoding)\n",
    "        question_encoding = TimeDistributed(\n",
    "            Dense(W,\n",
    "                use_bias=False,\n",
    "                trainable=True,\n",
    "                weights=np.concatenate((np.eye(W),np.eye(W)), axis=1))) (question_encoding)\n",
    "\n",
    "        '''Attention over question'''\n",
    "        # compute the importance of each step\n",
    "        question_attention_vector = TimeDistributed(Dense(1))(question_encoding)\n",
    "        question_attention_vector = Lambda(lambda q: keras.activations.softmax(q, axis=1))(question_attention_vector)\n",
    "\n",
    "        # apply the attention\n",
    "        question_attention_vector = Lambda(lambda q: q[0]*q[1])([question_encoding, question_attention_vector])\n",
    "        question_attention_vector = Lambda(lambda q: K.sum(q, axis=1))(question_attention_vector)\n",
    "        question_attention_vector = RepeatVector(N)(question_attention_vector)\n",
    "\n",
    "        '''Answer span prediction'''\n",
    "\n",
    "        # Answer start prediction\n",
    "        answer_start = Lambda(lambda arg:\n",
    "                              concatenate([arg[0], arg[1], arg[2]]))([\n",
    "            passage_encoding,\n",
    "            question_attention_vector,\n",
    "            multiply([passage_encoding, question_attention_vector])])\n",
    "\n",
    "        answer_start = TimeDistributed(Dense(W, activation='relu'))(answer_start)\n",
    "        answer_start = TimeDistributed(Dense(1))(answer_start)\n",
    "        answer_start = Flatten()(answer_start)\n",
    "        answer_start = Activation('softmax')(answer_start)\n",
    "\n",
    "        # Answer end prediction depends on the start prediction\n",
    "        def s_answer_feature(x):\n",
    "            maxind = K.argmax(\n",
    "                x,\n",
    "                axis=1,\n",
    "            )\n",
    "            return maxind\n",
    "\n",
    "        x = Lambda(lambda x: K.tf.cast(s_answer_feature(x), dtype=K.tf.int32))(answer_start)\n",
    "        start_feature = Lambda(lambda arg: K.tf.gather_nd(arg[0], K.tf.stack([K.tf.range(K.tf.shape(arg[1])[0]), K.tf.cast(arg[1], K.tf.int32)], axis=1)))([passage_encoding,x])\n",
    "        start_feature = RepeatVector(N)(start_feature)\n",
    "\n",
    "        # Answer end prediction\n",
    "        answer_end = Lambda(lambda arg: concatenate([\n",
    "            arg[0],\n",
    "            arg[1],\n",
    "            arg[2],\n",
    "            multiply([arg[0], arg[1]]),\n",
    "            multiply([arg[0], arg[2]])\n",
    "        ]))([passage_encoding, question_attention_vector, start_feature])\n",
    "\n",
    "        answer_end = TimeDistributed(Dense(W, activation='relu'))(answer_end)\n",
    "        answer_end = TimeDistributed(Dense(1))(answer_end)\n",
    "        answer_end = Flatten()(answer_end)\n",
    "        answer_end = Activation('softmax')(answer_end)\n",
    "\n",
    "        input_placeholders = [P, Q]\n",
    "        inputs = input_placeholders\n",
    "        outputs = [answer_start, answer_end]\n",
    "\n",
    "        super(FastQA, self).__init__(inputs=inputs,\n",
    "                                   outputs=outputs,\n",
    "                                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastQA(hdim=args['hdim'], dropout_rate=args['dropout'], N=300, M=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_config = {'class_name': args['optimizer'],\n",
    "                    'config': {'lr': args['lr']} if args['lr'] else {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer_config,\n",
    "              loss=args['loss'],\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f4033ba4f50>,\n",
       " <keras.engine.topology.InputLayer at 0x7f4033ba4f90>,\n",
       " <keras.layers.wrappers.Bidirectional at 0x7f4027f25990>,\n",
       " <keras.layers.wrappers.TimeDistributed at 0x7f4027871510>,\n",
       " <keras.layers.wrappers.TimeDistributed at 0x7f4027768050>,\n",
       " <keras.layers.core.Lambda at 0x7f40277680d0>,\n",
       " <keras.layers.core.Lambda at 0x7f4027768b50>,\n",
       " <keras.layers.core.Lambda at 0x7f4027780ed0>,\n",
       " <keras.layers.wrappers.TimeDistributed at 0x7f4027b388d0>,\n",
       " <keras.layers.core.RepeatVector at 0x7f4027780d90>,\n",
       " <keras.layers.merge.Multiply at 0x7f402773e150>,\n",
       " <keras.layers.core.Lambda at 0x7f4027793f10>,\n",
       " <keras.layers.wrappers.TimeDistributed at 0x7f4027750850>,\n",
       " <keras.layers.wrappers.TimeDistributed at 0x7f40276e4050>,\n",
       " <keras.layers.core.Flatten at 0x7f4027816710>,\n",
       " <keras.layers.core.Activation at 0x7f40276f8b90>,\n",
       " <keras.layers.core.Lambda at 0x7f402770c210>,\n",
       " <keras.layers.core.Lambda at 0x7f40276b9810>,\n",
       " <keras.layers.core.RepeatVector at 0x7f40276b9210>,\n",
       " <keras.layers.core.Lambda at 0x7f40276d1a90>,\n",
       " <keras.layers.wrappers.TimeDistributed at 0x7f4027691410>,\n",
       " <keras.layers.wrappers.TimeDistributed at 0x7f4027625f10>,\n",
       " <keras.layers.core.Flatten at 0x7f4027625510>,\n",
       " <keras.layers.core.Activation at 0x7f402763a790>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все работает теперь. Мешала wiq в коде модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
